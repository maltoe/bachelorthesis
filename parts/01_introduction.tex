\section{Introduction}
In the early days of general-purpose computing, processor power and time were scarce resources. Expensive, room-filling mainframes were often shared among numerous people and thus their utilization needed to be as efficient and time-saving as possible.   Performance, in terms of both minimum processor cycles and memory comsumption, was a critical feature for any software written in those days. Then, with the emergence of the personal computer and fast general-purpose processors, application performance became far less important and programmers began to pay less attention to it when designing their applications. Today, small computer towers sitting below everyone's desk outperform all of those early mainframes and provide more than enough processor power for most everyday use cases. When it comes to creating usual desktop applications or low-scale web applications, programmers can treat both memory and CPU power as effectivly abundant resources. However, there is still a plenty of cases where software performance matters to the user or even is a critical property of the application. For instance, in multimedia applications, video games, or embedded systems good performance is absolutely needed to establish a pleasant user experience. Scientific computing or industry control systems may rely on high or even real-time performance to serve their purpose at all.

Although computer science lecturers tend to reduce software performance to asymptotic complexity, the so-called \emph{constant factor} [ZITAT quicksrt] plays an at least equally important role in real-world applications. Therefore, the knowledge of various software optimization techniques remains a vital part of every programmer's profile. Knowing about how the CPU, its caches, and the memory work internally helps to understand where to find bottlenecks and how to avoid them. Some optimization techniques are mere guidelines that should be remembered and considered whenever writing a piece of software, whereas others are rather advanced measures only useful in special, rare situations. Lately, with processor speeds apparently having reached their limits at around 3-4 GHz, parallelization techniques have been brought into focus by CPU manufacturers and researchers alike. Both Intel and AMD have started to primarily ship multi-core processors in their end user product segments. These processors' superior performances obviously rely on the programmer to produce parallelized applications. 

Apart from that, most modern x86 descendants feature extended instruction sets that allow for data-parallelism. These SIMD (single instruction, multiple data) instructions enable the programmer to issue only one instruction to process multiple data values at a time. Introduced by Intel for the Pentium III in 1999 and later adopted by AMD, the SSE (Streaming SIMD Extensions) extension has become the most advanced and wide-spread SIMD technology available. While it was originally conceived to support multimedia processing and thus mainly contained multimedia specific instructions, it matured over time and became an almost fully-fledged vector processing unit. Processors implementing the latest SSE incarnation, SSE4, feature 16 \emph{media registers} called \texttt{xmm0} to \texttt{xmm15}, each of them 128 bits wide, and numerous instructions for parallel floating point and integer calculations. For example, using these, the programmer can choose to calculate the square root of 4 32 bit floating point values within a single instruction which would take about the same amount of time as its scalar counterpart. However, using SIMD extensions for optimization work falls into the second category of optimization techniques mentioned above. These instructions only turn to account in situations where one has highly parallelized applications preferably consisting of mostly calculation intensive code.

In the following bachelor thesis I am going to show how applying various optimization techniques can greatly improve performance of a real-world application. I will focus on floating point operations using SSE and how to circumvent the pitfalls arising from it. The thesis is outlined as follows: In section \ref{Related_work} I will provide some notable related work done in this area. In section \ref{Optimization_theory} I will name several basic optimization principles as well as general ideas of how to exploit SSE. Hereafter, in section \ref{Implementation} I will describe how I applied these techniques to the LS$^{2}$ simulation suite, evaluating the measures with empiric benchmarks results in section \ref{Evalution}. A conclusion will be given in section \ref{Conclusion}.
