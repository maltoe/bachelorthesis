\section{Conclusion}
\label{Conclusion}
In this thesis, I have shown how real-world algorithms can be optimized using SSE vector intrinsics. I described the theoretical background in Section~\ref{Optimization_theory} and conducted a case-study on the LS$^{2}$ simulation engine in Section~\ref{Implementation}.

The results of this case-study, as discussed in Section~\ref{Evaluation}, have been highly rewarding. Especially the \emph{Adapted Multilateration} algorithm has extremely benefited from the applied vectorization, with the achieved average speed-up of 3.3 being close to the theoretical maximum speed-up of 4. In other words, the average runtimes of the algorithm could be reduced to a third of the runtimes of the original implementation. Likewise, the performances of both VBLE-OPT and Geolateration, in spite of these algorithms being far more complex with regard to the control flow, could be drastically improved.

From the outcome of the case-study, one can further observe two simple facts: First, although compiler optimization may be sufficient for a decent performance of the average application, manual code optimization may still yield significant performance gains in computationally intensive applications. Today, modern compilers equipped with auto-vectorization features are able to automatically vectorize simple loops using SSE instructions, yet they lack the comprehensive view over an algorithm that is needed to identify vectorization opportunities as complex as demonstrated in the LS$^{2}$ optimization. Auto-vectorization will remain an attractive research topic in the future and it will be interesting to see how auto-vectorization techniques will be adapted to cope with more complex situations. However, it is worth mentioning, that in some situations the compiler will never be able to decide whether vectorization is a valid option, as it may require changes to the algorithm's functionality.

Second, the results show vividly that the capabilities of modern processors --- especially the integrated SIMD technology --- are not at all used to their full potentials. Even though the LS$^{2}$ application had been optimized already and was compiled with compiler optimization set to its highest level, I was able to \emph{triple} the performance of AML on the same hardware. To emphasize this point even more, the same result could have been achieved by installing two additional processors of the same kind into the system, disregarding any memory bandwidth limitations. 

Certainly, the potential impact of SSE optimization largely depends on the inherent data-parallelism of a particular algorithm. If an algorithm contains overly many conditional jumps or processes data in totally random patterns, vectorization is difficult to do and is very likely to have no advantageous effects on the algorithm's performance. Similarly, algorithms whose performance is entirely limited by memory bandwith will rarely benefit from vectorization. The LS$^{2}$ engine, by contrast, has proven an ideal application to be enhanced by SSE optimization, as its main functionality, the endlessly repeated position estimation using lateration algorithms, could be perfectly parallelized. Additionally, since the implemented algorithms are not subjected to future changes, the increased complexity and reduced readability that come along with SSE optimization are not as problematic as they might be for other applications, for which it should be decided on a case-by-case basis whether SSE vectorization as well as manual optimization in general is worth the effort.
